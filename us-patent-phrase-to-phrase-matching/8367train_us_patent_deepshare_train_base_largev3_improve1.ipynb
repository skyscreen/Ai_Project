{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp8fCwLA6cHc",
        "outputId": "d112653b-26de-4044-fc40-600aaa75479d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n",
        "import shutil\n",
        "import time\n",
        "import gc\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import transformers\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForWholeWordMask\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBAwTRQJ6cHk"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWgfP10T6cHn"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    input_path = '/content/drive/MyDrive/us-patent/'\n",
        "#     model_path = 'microsoft/deberta-v3-small' #  nghuyong/ernie-2.0-large-en studio-ousia/luke-large\n",
        "    # model_path = '/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large'\n",
        "    model_path = '/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large'\n",
        "    # model_path = '/content/drive/MyDrive/us-patent/deberta-v3-small' \n",
        "    # model_path_save = '/content/drive/MyDrive/us-patent/smallmodel/',\n",
        "    model_path_save = '/content/drive/MyDrive/us-patent/tmp/large4/',   \n",
        "\n",
        "    scheduler = 'cosine'  # ['linear', 'cosine']\n",
        "    batch_scheduler = True\n",
        "    num_cycles = 0.5  # 1.5\n",
        "    num_warmup_steps = 0.1\n",
        "    max_input_length = 140\n",
        "    epochs = 4  # 5\n",
        "    min_lr = 0.5e-6\n",
        "    eps = 1e-6\n",
        "    betas = (0.9, 0.999)\n",
        "    learning_rate = 2e-5\n",
        "    weight_decay = 0.01\n",
        "    num_fold = 4\n",
        "    batch_size = 8#100\n",
        "    seed = 86#19800102\n",
        "    OUTPUT_DIR = './train_checkpoint'\n",
        "    num_workers = 2#2\n",
        "    device='cuda'\n",
        "    print_freq = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3XAjUX97x_A",
        "outputId": "71a0e386-5298-4199-9058-adcd92de3034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auEjKpT36cHq"
      },
      "source": [
        "## logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mf28bix6cHr",
        "outputId": "e46f7abc-619d-40fc-b910-7448860fee8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "===============lr_2e-05===============\n",
            "===============lr_2e-05===============\n",
            "===============seed_86===============\n",
            "===============seed_86===============\n",
            "===============total_epochs_4===============\n",
            "===============total_epochs_4===============\n",
            "===============num_warmup_steps_0.1===============\n",
            "===============num_warmup_steps_0.1===============\n"
          ]
        }
      ],
      "source": [
        "def get_logger(filename=CFG.OUTPUT_DIR+ 'train'):\n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = get_logger()\n",
        "LOGGER.info('===============lr_{}==============='.format(CFG.learning_rate))\n",
        "LOGGER.info('===============seed_{}==============='.format(CFG.seed))\n",
        "LOGGER.info('===============total_epochs_{}==============='.format(CFG.epochs))\n",
        "LOGGER.info('===============num_warmup_steps_{}==============='.format(CFG.num_warmup_steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW-u6QcD8V3M"
      },
      "outputs": [],
      "source": [
        "# ! pip install kaggle\n",
        "# ! mkdir ~/.kaggle\n",
        "# ! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d helloggfss/foldsdump\n",
        "# !unzip /content/foldsdump.zip -d /content/drive/MyDrive/us-patent/folds-dump-the-two-paths-fix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFpoiZp6cHu"
      },
      "source": [
        "# Preproc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "_KW9BpUm6cHu",
        "outputId": "9a63bf63-b068-42ce-c185-9fbdf412f7c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "fold\n",
              "0    9119\n",
              "1    9118\n",
              "2    9118\n",
              "3    9118\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# improve1\n",
        "# ====================================================\n",
        "# CV split\n",
        "# ====================================================\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/us-patent/us-patent-phrase-to-phrase-matching/train.csv\")\n",
        "cpc_texts = torch.load(\"/content/drive/MyDrive/us-patent/folds-dump-the-two-paths-fix/cpc_texts_fixed.pth\")\n",
        "train_df['context_text'] = train_df['context'].map(cpc_texts)\n",
        "\n",
        "train_df['score_map'] = train_df['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n",
        "Fold = StratifiedKFold(n_splits=CFG.num_fold, shuffle=True, random_state=CFG.seed)\n",
        "# for n, (train_index, val_index) in enumerate(Fold.split(train_df, train_df['score_map'])):\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train_df, train_df['anchor'])):\n",
        "    train_df.loc[val_index, 'fold'] = int(n)\n",
        "train_df['fold'] = train_df['fold'].astype(int)\n",
        "display(train_df.groupby('fold').size())\n",
        "train_df['input'] = train_df['anchor'] + ' ' + train_df['context_text'].apply(str.lower) + ' ' + train_df['target'].apply(str.lower)\n",
        "\n",
        "\n",
        "# train_df = pd.read_csv(\"/content/drive/MyDrive/us-patent/folds-dump-the-two-paths-fix/train_folds_5.csv\")\n",
        "# train_df['input'] = train_df['anchor'] + ' ' + train_df['context_text_fix'].apply(str.lower) + ' ' + train_df['target'].apply(str.lower)\n",
        "# train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cp4AIl3w6cHw",
        "outputId": "dd20a08b-4632-4ea7-8ecc-d7e197ae07b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5a9395e4-d991-4822-b4bd-9834efc8c14e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>context_text</th>\n",
              "      <th>score_map</th>\n",
              "      <th>fold</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37d61fd2272659b1</td>\n",
              "      <td>abatement</td>\n",
              "      <td>abatement of pollution</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>abatement human necessities. furniture; domest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7b9652b17b68b7a4</td>\n",
              "      <td>abatement</td>\n",
              "      <td>act of abating</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.75</td>\n",
              "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>abatement human necessities. furniture; domest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36d72442aefd8232</td>\n",
              "      <td>abatement</td>\n",
              "      <td>active catalyst</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.25</td>\n",
              "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>abatement human necessities. furniture; domest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5296b0c19e1ce60e</td>\n",
              "      <td>abatement</td>\n",
              "      <td>eliminating process</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>abatement human necessities. furniture; domest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54c1e3b9184cb5b6</td>\n",
              "      <td>abatement</td>\n",
              "      <td>forest region</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>abatement human necessities. furniture; domest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36468</th>\n",
              "      <td>8e1386cbefd7f245</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden article</td>\n",
              "      <td>B44</td>\n",
              "      <td>1.00</td>\n",
              "      <td>PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>wood article performing operations; transporti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36469</th>\n",
              "      <td>42d9e032d1cd3242</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden box</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.50</td>\n",
              "      <td>PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>wood article performing operations; transporti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36470</th>\n",
              "      <td>208654ccb9e14fa3</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden handle</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.50</td>\n",
              "      <td>PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>wood article performing operations; transporti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36471</th>\n",
              "      <td>756ec035e694722b</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden material</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.75</td>\n",
              "      <td>PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>wood article performing operations; transporti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36472</th>\n",
              "      <td>8d135da0b55b8c88</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden substrate</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.50</td>\n",
              "      <td>PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>wood article performing operations; transporti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36473 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a9395e4-d991-4822-b4bd-9834efc8c14e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a9395e4-d991-4822-b4bd-9834efc8c14e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a9395e4-d991-4822-b4bd-9834efc8c14e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     id        anchor                  target context  score  \\\n",
              "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n",
              "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n",
              "2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n",
              "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n",
              "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n",
              "...                 ...           ...                     ...     ...    ...   \n",
              "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00   \n",
              "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50   \n",
              "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50   \n",
              "36471  756ec035e694722b  wood article         wooden material     B44   0.75   \n",
              "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50   \n",
              "\n",
              "                                            context_text  score_map  fold  \\\n",
              "0      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          2     0   \n",
              "1      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          3     3   \n",
              "2      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          1     2   \n",
              "3      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          2     0   \n",
              "4      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          0     0   \n",
              "...                                                  ...        ...   ...   \n",
              "36468  PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...          4     1   \n",
              "36469  PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...          2     1   \n",
              "36470  PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...          2     2   \n",
              "36471  PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...          3     1   \n",
              "36472  PERFORMING OPERATIONS; TRANSPORTING. DECORATIV...          2     0   \n",
              "\n",
              "                                                   input  \n",
              "0      abatement human necessities. furniture; domest...  \n",
              "1      abatement human necessities. furniture; domest...  \n",
              "2      abatement human necessities. furniture; domest...  \n",
              "3      abatement human necessities. furniture; domest...  \n",
              "4      abatement human necessities. furniture; domest...  \n",
              "...                                                  ...  \n",
              "36468  wood article performing operations; transporti...  \n",
              "36469  wood article performing operations; transporti...  \n",
              "36470  wood article performing operations; transporti...  \n",
              "36471  wood article performing operations; transporti...  \n",
              "36472  wood article performing operations; transporti...  \n",
              "\n",
              "[36473 rows x 9 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oml40jZ76cHx"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC5hWknW6cHy",
        "outputId": "c1879130-8b7b-43e0-f925-e305c34c0fd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Didn't find file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/tokenizer.json. We won't load it.\n",
            "Didn't find file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/added_tokens.json. We won't load it.\n",
            "Didn't find file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/special_tokens_map.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/spm.model\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Adding [MASK] to the vocabulary\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3aq2SX46cHz"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaqIPYES6cHz"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = df['input'].values.astype(str)\n",
        "        \n",
        "        self.label = df['score'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = self.texts[item]\n",
        "        label = self.label[item]\n",
        "        \n",
        "        \n",
        "        inputs = tokenizer(text,\n",
        "                    max_length=CFG.max_input_length,\n",
        "                    padding='max_length',\n",
        "                    truncation=True )\n",
        "        return {**inputs,\n",
        "               'labels':torch.as_tensor(label, dtype=torch.float) }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfxDvXCA6cH0"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUUb_EOC6cH0"
      },
      "outputs": [],
      "source": [
        "class Custom_Bert_Simple(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(CFG.model_path)\n",
        "        self.base = AutoModelForSequenceClassification.from_pretrained(CFG.model_path, num_labels=1)\n",
        "        dim = config.hidden_size\n",
        "        self.dropout = nn.Dropout(p=0)\n",
        "        self.cls = nn.Linear(dim,1)\n",
        "        \n",
        "    def forward(self, input_ids, token_type_ids ,attention_mask, labels=None):\n",
        "        base_output = self.base(input_ids=input_ids,\n",
        "                                attention_mask=attention_mask,\n",
        "                                token_type_ids=token_type_ids\n",
        "                               )\n",
        "\n",
        "        output = base_output[0]\n",
        "        if labels is None:\n",
        "            return output\n",
        "        \n",
        "        else:\n",
        "            return (nn.MSELoss()(torch.squeeze(output,1),labels), output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNfT1sq26cH1",
        "outputId": "9035aa87-2169-400f-e10a-bee585ad1ad0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/pytorch_model.bin\n",
            "Some weights of the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(CFG.model_path, num_labels=1)\n",
        "model = Custom_Bert_Simple()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOAkPDR-6cH1"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_kCBLxC6cH2"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        loss, logits = outputs\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5q0P5fx6cH2"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_BDp-Ev6cH2"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    torch.cuda.empty_cache()\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.reshape(len(predictions))\n",
        "    torch.cuda.empty_cache()\n",
        "    return {\n",
        "        'pearson': np.corrcoef(predictions, labels)[0][1]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tOfH3If6cH3"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything(CFG.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e5896e71192244d7bc63f2377cd630ac",
            "e0a4181737324d25aa8d83cdea641930",
            "df9f2db01c584238b1d68ae1ce2bdf3e",
            "c90763f2eb7341eb9b7410cfd422c2c0",
            "48eeceffa6b846dd89116a6214bce438",
            "eddddca53fae4c48ab24a933d1c1d35f",
            "696d3968bbf8493fba41306ec9a4e90a",
            "c81360c6ea7b46dda0f5ab46c4593282",
            "a93a2804420d415889c3af136731e6e6",
            "7f1440a51587401584740c1d093add25",
            "672be96f4eb44a7caa1de6f034a0b7de",
            "eb25aa4f57ae448b94ef1ad8200c6ec1",
            "e1e5eda523fa445398ad8f19ccc90231",
            "1fe80f648b244406bbe548103b27c9f3",
            "62310ec8db0248b6a9c83dc300ae8c82",
            "c8d4fc3f2003407ea31d136ce5a7a9ee",
            "e3f85743a8a743999ab28167425acbe5",
            "843c5ede4319424996f753c2fda46ca9",
            "1f52daaa316b478aaaa695d65385ecfc",
            "e7470f5d08704b7e90cfe64812cab7dd",
            "6813900c3a03470ba888e6b26c7b8c73",
            "ecb12af5432a4d6bb4232c3545991b00",
            "5490bce98aa5405f819cca596f183654",
            "f04b856afb3e4455b6927c7acfcae1ce",
            "5b71a0a6c1fd4b40a8c52c3232c47379",
            "b76b9565af874841aaeddb8353e366e6",
            "207681f8328f4b67a229505d2456ca02",
            "8b4ebebe7e004eb5b57dedf0ef2956fd",
            "2691343aeaa24b77b23e76702fa9f9ef",
            "affcff663c0b4ed0ada9bcf79d7e4437",
            "0ff91fb13e0741328996ece3ceafec5e",
            "8fc0b78f32ac410599637b7b92d6ab0c",
            "61753da0773c4ea390cef717a6e8c633"
          ]
        },
        "id": "y2dFM1mN6cH4",
        "outputId": "e52acbc1-51d7-4279-fec1-77f69be7b6fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5896e71192244d7bc63f2377cd630ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/136 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb25aa4f57ae448b94ef1ad8200c6ec1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/36473 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5490bce98aa5405f819cca596f183654",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/36473 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_input_length: 133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 27354\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13680\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13680' max='13680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13680/13680 2:26:46, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.028700</td>\n",
              "      <td>0.021961</td>\n",
              "      <td>0.826604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.019102</td>\n",
              "      <td>0.852095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.010700</td>\n",
              "      <td>0.018592</td>\n",
              "      <td>0.862855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>0.017269</td>\n",
              "      <td>0.869591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 9119\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-3420\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-3420/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-3420/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9119\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-6840\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-6840/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-6840/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9119\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-10260\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-10260/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-10260/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-3420] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9119\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-13680\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-13680/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-13680/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-6840] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_checkpoint/checkpoint-13680 (score: 0.8695913701411886).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 9119\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1140/1140 03:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_input_length: 133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 27355\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13680\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13680' max='13680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13680/13680 2:26:36, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.028600</td>\n",
              "      <td>0.025120</td>\n",
              "      <td>0.817319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.018700</td>\n",
              "      <td>0.018573</td>\n",
              "      <td>0.850843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.010900</td>\n",
              "      <td>0.019459</td>\n",
              "      <td>0.858433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.007100</td>\n",
              "      <td>0.018749</td>\n",
              "      <td>0.862600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-3420\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-3420/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-3420/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-6840\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-6840/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-6840/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-10260\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-10260/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-10260/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-3420] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-13680\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-13680/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-13680/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-6840] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_checkpoint/checkpoint-13680 (score: 0.8625999826715574).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1140/1140 03:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_input_length: 133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 27355\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13680\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13680' max='13680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13680/13680 2:26:41, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.069100</td>\n",
              "      <td>0.044908</td>\n",
              "      <td>0.615735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.025300</td>\n",
              "      <td>0.020698</td>\n",
              "      <td>0.833496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.014700</td>\n",
              "      <td>0.019385</td>\n",
              "      <td>0.848352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.018625</td>\n",
              "      <td>0.858854</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-3420\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-3420/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-3420/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-6840\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-6840/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-6840/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-10260\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-10260/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-10260/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-3420] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-13680\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-13680/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-13680/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-6840] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_checkpoint/checkpoint-13680 (score: 0.858854071857711).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1140/1140 03:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading configuration file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_input_length: 133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/us-patent/deberta-v3-large/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 27355\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13680\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13680' max='13680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13680/13680 2:26:33, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.029150</td>\n",
              "      <td>0.807015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.017100</td>\n",
              "      <td>0.020945</td>\n",
              "      <td>0.836199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.011400</td>\n",
              "      <td>0.019106</td>\n",
              "      <td>0.852812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.018391</td>\n",
              "      <td>0.857934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-3420\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-3420/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-3420/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-6840\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-6840/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-6840/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-10260\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-10260/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-10260/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-3420] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./train_checkpoint/checkpoint-13680\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "tokenizer config file saved in ./train_checkpoint/checkpoint-13680/tokenizer_config.json\n",
            "Special tokens file saved in ./train_checkpoint/checkpoint-13680/special_tokens_map.json\n",
            "Deleting older checkpoint [train_checkpoint/checkpoint-6840] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_checkpoint/checkpoint-13680 (score: 0.8579342832587028).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 9118\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1140/1140 03:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# improve1\n",
        "# ====================================================\n",
        "# Define max_len\n",
        "# ====================================================\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "lengths_dict = {}\n",
        "\n",
        "lengths = []\n",
        "tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n",
        "for text in tk0:\n",
        "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "    lengths.append(length)\n",
        "lengths_dict['context_text'] = lengths\n",
        "\n",
        "for text_col in ['anchor', 'target']:\n",
        "    lengths = []\n",
        "    tk0 = tqdm(train_df[text_col].fillna(\"\").values, total=len(train_df))\n",
        "    for text in tk0:\n",
        "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "        lengths.append(length)\n",
        "    lengths_dict[text_col] = lengths\n",
        "\n",
        "oof_df = pd.DataFrame()\n",
        "for fold in range(CFG.num_fold):\n",
        "    \n",
        "    #improve1\n",
        "    CFG.max_input_length = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n",
        "                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n",
        "    print(f\"max_input_length: {CFG.max_input_length}\")    \n",
        "\n",
        "    tr_data = train_df[train_df['fold']!=fold].reset_index(drop=True)\n",
        "    va_data = train_df[train_df['fold']==fold].reset_index(drop=True)\n",
        "    tr_dataset = TrainDataset(tr_data)\n",
        "    va_dataset = TrainDataset(va_data)\n",
        "    args = TrainingArguments(\n",
        "        CFG.OUTPUT_DIR,\n",
        "        evaluation_strategy = \"epoch\",\n",
        "        save_strategy = \"epoch\",\n",
        "        learning_rate=CFG.learning_rate,\n",
        "        per_device_train_batch_size=CFG.batch_size,\n",
        "        per_device_eval_batch_size=CFG.batch_size,\n",
        "        num_train_epochs=CFG.epochs,\n",
        "        weight_decay=CFG.weight_decay,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"pearson\",\n",
        "        save_total_limit=1,\n",
        "        warmup_ratio=CFG.num_warmup_steps\n",
        "    )\n",
        "    model = Custom_Bert_Simple()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    trainer = CustomTrainer(\n",
        "        model,\n",
        "        args,\n",
        "        train_dataset=tr_dataset,\n",
        "        eval_dataset=va_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    torch.cuda.empty_cache()    \n",
        "    trainer.train()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    outputs = trainer.predict(va_dataset)\n",
        "    predictions = outputs.predictions.reshape(-1)\n",
        "    va_data['preds'] = predictions\n",
        "    torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        # '/content/drive/MyDrive/us-patent/smallmodel/' + \"{}_best{}.pth\".format(CFG.model_path.replace('/', '_'),fold))\n",
        "                       '/content/drive/MyDrive/us-patent/tmp/large4/' + \"{}_best{}.pth\".format(CFG.model_path.replace('/', '_'),fold))\n",
        "\n",
        "    shutil.rmtree(CFG.OUTPUT_DIR)\n",
        "    oof_df = pd.concat([oof_df, va_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TOQsEfnm6cH5",
        "outputId": "6ee55f1a-4529-436f-8620-5a10dadbe202"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pearson': 0.8621580950996016}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = oof_df['preds'].values\n",
        "label = oof_df['score'].values\n",
        "eval_pred = predictions, label\n",
        "compute_metrics(eval_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eqIX1EQS6cH6"
      },
      "outputs": [],
      "source": [
        "oof_df.to_csv('/content/drive/MyDrive/us-patent/tmp/large4/oof_df.csv')\n",
        "oof_df.to_pickle('/content/drive/MyDrive/us-patent/tmp/large4/oof_df.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "train_us_patent_deepshare_train_base_largev3_improve1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ff91fb13e0741328996ece3ceafec5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f52daaa316b478aaaa695d65385ecfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe80f648b244406bbe548103b27c9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f52daaa316b478aaaa695d65385ecfc",
            "max": 36473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7470f5d08704b7e90cfe64812cab7dd",
            "value": 36473
          }
        },
        "207681f8328f4b67a229505d2456ca02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2691343aeaa24b77b23e76702fa9f9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48eeceffa6b846dd89116a6214bce438": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5490bce98aa5405f819cca596f183654": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f04b856afb3e4455b6927c7acfcae1ce",
              "IPY_MODEL_5b71a0a6c1fd4b40a8c52c3232c47379",
              "IPY_MODEL_b76b9565af874841aaeddb8353e366e6"
            ],
            "layout": "IPY_MODEL_207681f8328f4b67a229505d2456ca02"
          }
        },
        "5b71a0a6c1fd4b40a8c52c3232c47379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affcff663c0b4ed0ada9bcf79d7e4437",
            "max": 36473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ff91fb13e0741328996ece3ceafec5e",
            "value": 36473
          }
        },
        "61753da0773c4ea390cef717a6e8c633": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62310ec8db0248b6a9c83dc300ae8c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6813900c3a03470ba888e6b26c7b8c73",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb12af5432a4d6bb4232c3545991b00",
            "value": " 36473/36473 [00:04&lt;00:00, 8043.08it/s]"
          }
        },
        "672be96f4eb44a7caa1de6f034a0b7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6813900c3a03470ba888e6b26c7b8c73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696d3968bbf8493fba41306ec9a4e90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1440a51587401584740c1d093add25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "843c5ede4319424996f753c2fda46ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4ebebe7e004eb5b57dedf0ef2956fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc0b78f32ac410599637b7b92d6ab0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a93a2804420d415889c3af136731e6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "affcff663c0b4ed0ada9bcf79d7e4437": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76b9565af874841aaeddb8353e366e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc0b78f32ac410599637b7b92d6ab0c",
            "placeholder": "​",
            "style": "IPY_MODEL_61753da0773c4ea390cef717a6e8c633",
            "value": " 36473/36473 [00:04&lt;00:00, 8363.63it/s]"
          }
        },
        "c81360c6ea7b46dda0f5ab46c4593282": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d4fc3f2003407ea31d136ce5a7a9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90763f2eb7341eb9b7410cfd422c2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1440a51587401584740c1d093add25",
            "placeholder": "​",
            "style": "IPY_MODEL_672be96f4eb44a7caa1de6f034a0b7de",
            "value": " 136/136 [00:00&lt;00:00, 1763.02it/s]"
          }
        },
        "df9f2db01c584238b1d68ae1ce2bdf3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c81360c6ea7b46dda0f5ab46c4593282",
            "max": 136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a93a2804420d415889c3af136731e6e6",
            "value": 136
          }
        },
        "e0a4181737324d25aa8d83cdea641930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eddddca53fae4c48ab24a933d1c1d35f",
            "placeholder": "​",
            "style": "IPY_MODEL_696d3968bbf8493fba41306ec9a4e90a",
            "value": "100%"
          }
        },
        "e1e5eda523fa445398ad8f19ccc90231": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f85743a8a743999ab28167425acbe5",
            "placeholder": "​",
            "style": "IPY_MODEL_843c5ede4319424996f753c2fda46ca9",
            "value": "100%"
          }
        },
        "e3f85743a8a743999ab28167425acbe5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5896e71192244d7bc63f2377cd630ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0a4181737324d25aa8d83cdea641930",
              "IPY_MODEL_df9f2db01c584238b1d68ae1ce2bdf3e",
              "IPY_MODEL_c90763f2eb7341eb9b7410cfd422c2c0"
            ],
            "layout": "IPY_MODEL_48eeceffa6b846dd89116a6214bce438"
          }
        },
        "e7470f5d08704b7e90cfe64812cab7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb25aa4f57ae448b94ef1ad8200c6ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1e5eda523fa445398ad8f19ccc90231",
              "IPY_MODEL_1fe80f648b244406bbe548103b27c9f3",
              "IPY_MODEL_62310ec8db0248b6a9c83dc300ae8c82"
            ],
            "layout": "IPY_MODEL_c8d4fc3f2003407ea31d136ce5a7a9ee"
          }
        },
        "ecb12af5432a4d6bb4232c3545991b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eddddca53fae4c48ab24a933d1c1d35f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04b856afb3e4455b6927c7acfcae1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4ebebe7e004eb5b57dedf0ef2956fd",
            "placeholder": "​",
            "style": "IPY_MODEL_2691343aeaa24b77b23e76702fa9f9ef",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}