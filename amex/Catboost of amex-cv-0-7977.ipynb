{"cells":[{"cell_type":"markdown","metadata":{"id":"V8TX5ncPVNY3"},"source":["# Comments:\n","    \n","This is an improvement of my baseline, you can find it here: https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7963\n","\n","The main difference between this solution and previous one is that we add new features and do seed blend to boost LB. Single 5 kfold model using seed 42 achieve an out of folds CV of 0.7977 and a public leaderboard of 0.799. If we use seed blend (train three different models using seed 42, 52, 62 and then average predictions) the LB boost niceley.\n","\n","The main features that boost CV are the following:\n","\n","* The difference between last value and the lag1\n","* The difference between last value and the average (this features gives a nice boost)\n","\n","This feature engineer is done on all the last columns, so we actually add a lot of features, this model used 1368 features.\n","\n","I uploaded test predictions to avoid running training and inference\n","\n","Next Steps:\n","\n","* Could try feature selection, maybe a lot of the feature are just noise, actually I perform permutation importance and I reduce the amount of features to 1000 app and the CV was almost the same. Maybe there is a better feature selection technique that can boost performance.\n","\n","* Could try different models, maybe some neural network with the same features or a subset of the features and then blend with LGBM can work, in my experience blending tree models and neural network works great because they are very diverse so the boost is nice\n","\n","* Could try more feature engineering, maybe we can create more features that extract the hidden signal of the dataset, actually I would first work on this option and really try to capture all the signal that the dataset has."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U38gJrkJVPTd"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"oem3LtDHVNY_"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQ1JQbKOVNZA"},"outputs":[],"source":["# ====================================================\n","# Configurations\n","# ====================================================\n","class CFG:\n","    input_dir = '/content/drive/MyDrive/amex/output/7977o/'\n","    seed = 103\n","    n_folds = 5\n","    target = 'target'\n","    boosting_type = 'dart'\n","    metric = 'binary_logloss'\n","# ====================================================\n","# Library\n","# ====================================================\n","import gc\n","import warnings\n","warnings.filterwarnings('ignore')\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","import itertools\n","\n","# ====================================================\n","# Get the difference\n","# ====================================================\n","def get_difference(data, num_features):\n","    df1 = []\n","    customer_ids = []\n","    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n","        # Get the differences\n","        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n","        # Append to lists\n","        df1.append(diff_df1)\n","        customer_ids.append(customer_id)\n","    # Concatenate\n","    df1 = np.concatenate(df1, axis = 0)\n","    # Transform to dataframe\n","    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n","    # Add customer id\n","    df1['customer_ID'] = customer_ids\n","    return df1\n","\n","# ====================================================\n","# Read \u0026 preprocess data and save it to disk\n","# ====================================================\n","def read_preprocess_data():\n","    train = pd.read_parquet('/content/drive/MyDrive/amex/data/amex-data-integer-dtypes-parquet-format/train.parquet')\n","    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n","    cat_features = [\n","        \"B_30\",\n","        \"B_38\",\n","        \"D_114\",\n","        \"D_116\",\n","        \"D_117\",\n","        \"D_120\",\n","        \"D_126\",\n","        \"D_63\",\n","        \"D_64\",\n","        \"D_66\",\n","        \"D_68\",\n","    ]\n","    num_features = [col for col in features if col not in cat_features]\n","    print('Starting training feature engineer...')\n","    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n","    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n","    train_num_agg.reset_index(inplace = True)\n","    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n","    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n","    train_cat_agg.reset_index(inplace = True)\n","    train_labels = pd.read_csv('/content/drive/MyDrive/amex/data/train_labels.csv')\n","    # Transform float64 columns to float32\n","    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n","    for col in tqdm(cols):\n","        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n","    # Transform int64 columns to int32\n","    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n","    for col in tqdm(cols):\n","        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n","    # Get the difference\n","    train_diff = get_difference(train, num_features)\n","    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n","    del train_num_agg, train_cat_agg, train_diff\n","    gc.collect()\n","    test = pd.read_parquet('/content/drive/MyDrive/amex/data/amex-data-integer-dtypes-parquet-format/test.parquet')\n","    print('Starting test feature engineer...')\n","    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n","    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n","    test_num_agg.reset_index(inplace = True)\n","    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n","    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n","    test_cat_agg.reset_index(inplace = True)\n","    # Transform float64 columns to float32\n","    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n","    for col in tqdm(cols):\n","        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n","    # Transform int64 columns to int32\n","    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n","    for col in tqdm(cols):\n","        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n","    # Get the difference\n","    test_diff = get_difference(test, num_features)\n","    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n","    del test_num_agg, test_cat_agg, test_diff\n","    gc.collect()\n","    # Save files to disk\n","    train.to_parquet(CFG.input_dir + 'train_fe.parquet')\n","    test.to_parquet(CFG.input_dir + 'test_fe.parquet')\n","\n","# Read \u0026 Preprocess Data\n","# read_preprocess_data()"]},{"cell_type":"markdown","metadata":{"id":"Wzx0k3PfVNZC"},"source":["# Training \u0026 Inference"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6112281,"status":"ok","timestamp":1658044830343,"user":{"displayName":"darwin zhao","userId":"12087337285275609974"},"user_tz":-480},"id":"sGIYhM_AVNZD"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"931141d470b74db5baf74cc38bb59821","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1080 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" \n","--------------------------------------------------\n","Training fold 0 with 1365 features...\n","Learning rate set to 0.022138\n","0:\tlearn: 0.6655242\ttest: 0.6655077\tbest: 0.6655077 (0)\ttotal: 31.2ms\tremaining: 2m 35s\n","1000:\tlearn: 0.2155856\ttest: 0.2200759\tbest: 0.2200759 (1000)\ttotal: 26.1s\tremaining: 1m 44s\n","2000:\tlearn: 0.2082903\ttest: 0.2179098\tbest: 0.2179098 (2000)\ttotal: 50.6s\tremaining: 1m 15s\n","3000:\tlearn: 0.2027132\ttest: 0.2169255\tbest: 0.2169254 (2999)\ttotal: 1m 14s\tremaining: 49.8s\n","4000:\tlearn: 0.1976748\ttest: 0.2162629\tbest: 0.2162629 (4000)\ttotal: 1m 39s\tremaining: 24.7s\n","4999:\tlearn: 0.1928865\ttest: 0.2158227\tbest: 0.2158195 (4997)\ttotal: 2m 3s\tremaining: 0us\n","bestTest = 0.2158194932\n","bestIteration = 4997\n","Shrink model to first 4998 iterations.\n","Model has been saved\n","Our fold 0 CV score is 0.7948799420202948\n"," \n","--------------------------------------------------\n","Training fold 1 with 1365 features...\n","Learning rate set to 0.022138\n","0:\tlearn: 0.6654405\ttest: 0.6654228\tbest: 0.6654228 (0)\ttotal: 30.9ms\tremaining: 2m 34s\n","1000:\tlearn: 0.2148919\ttest: 0.2223824\tbest: 0.2223824 (1000)\ttotal: 26s\tremaining: 1m 43s\n","2000:\tlearn: 0.2076379\ttest: 0.2204719\tbest: 0.2204719 (2000)\ttotal: 50.4s\tremaining: 1m 15s\n","3000:\tlearn: 0.2020330\ttest: 0.2195534\tbest: 0.2195530 (2999)\ttotal: 1m 14s\tremaining: 49.7s\n","4000:\tlearn: 0.1969668\ttest: 0.2189305\tbest: 0.2189286 (3999)\ttotal: 1m 38s\tremaining: 24.6s\n","4999:\tlearn: 0.1922572\ttest: 0.2186003\tbest: 0.2186003 (4999)\ttotal: 2m 2s\tremaining: 0us\n","bestTest = 0.2186002965\n","bestIteration = 4999\n","Model has been saved\n","Our fold 1 CV score is 0.7922480199545845\n"," \n","--------------------------------------------------\n","Training fold 2 with 1365 features...\n","Learning rate set to 0.022138\n","0:\tlearn: 0.6649369\ttest: 0.6649271\tbest: 0.6649271 (0)\ttotal: 31.4ms\tremaining: 2m 37s\n","1000:\tlearn: 0.2155476\ttest: 0.2196857\tbest: 0.2196857 (1000)\ttotal: 26.1s\tremaining: 1m 44s\n","2000:\tlearn: 0.2083385\ttest: 0.2175520\tbest: 0.2175520 (2000)\ttotal: 50.3s\tremaining: 1m 15s\n","3000:\tlearn: 0.2026904\ttest: 0.2165414\tbest: 0.2165411 (2999)\ttotal: 1m 14s\tremaining: 49.6s\n","4000:\tlearn: 0.1976611\ttest: 0.2159557\tbest: 0.2159557 (3998)\ttotal: 1m 38s\tremaining: 24.6s\n","4999:\tlearn: 0.1928868\ttest: 0.2155588\tbest: 0.2155588 (4995)\ttotal: 2m 2s\tremaining: 0us\n","bestTest = 0.2155587517\n","bestIteration = 4995\n","Shrink model to first 4996 iterations.\n","Model has been saved\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import warnings\n","warnings.filterwarnings('ignore')\n","import random\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import itertools\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import lightgbm as lgb\n","from itertools import combinations\n","\n","\n","\n","# ====================================================\n","# Seed everything\n","# ====================================================\n","def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","# ====================================================\n","# Read data\n","# ====================================================\n","def read_data():\n","    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n","    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n","    return train, test\n","\n","# ====================================================\n","# Amex metric\n","# ====================================================\n","def amex_metric(y_true, y_pred):\n","    labels = np.transpose(np.array([y_true, y_pred]))\n","    labels = labels[labels[:, 1].argsort()[::-1]]\n","    weights = np.where(labels[:,0]==0, 20, 1)\n","    cut_vals = labels[np.cumsum(weights) \u003c= int(0.04 * np.sum(weights))]\n","    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n","    gini = [0,0]\n","    for i in [1,0]:\n","        labels = np.transpose(np.array([y_true, y_pred]))\n","        labels = labels[labels[:, i].argsort()[::-1]]\n","        weight = np.where(labels[:,0]==0, 20, 1)\n","        weight_random = np.cumsum(weight / np.sum(weight))\n","        total_pos = np.sum(labels[:, 0] *  weight)\n","        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n","        lorentz = cum_pos_found / total_pos\n","        gini[i] = np.sum((lorentz - weight_random) * weight)\n","    return 0.5 * (gini[1]/gini[0] + top_four)\n","\n","# ====================================================\n","# LGBM amex metric\n","# ====================================================\n","def lgb_amex_metric(y_pred, y_true):\n","    y_true = y_true.get_label()\n","    return 'amex_metric', amex_metric(y_true, y_pred), True\n","\n","# ====================================================\n","# Train \u0026 Evaluate\n","# ====================================================\n","def train_and_evaluate(train, test):\n","    # Label encode categorical features\n","    cat_features = [\n","        \"B_30\",\n","        \"B_38\",\n","        \"D_114\",\n","        \"D_116\",\n","        \"D_117\",\n","        \"D_120\",\n","        \"D_126\",\n","        \"D_63\",\n","        \"D_64\",\n","        \"D_66\",\n","        \"D_68\"\n","    ]\n","    cat_features = [f\"{cf}_last\" for cf in cat_features]\n","    for cat_col in cat_features:\n","        encoder = LabelEncoder()\n","        train[cat_col] = encoder.fit_transform(train[cat_col])\n","        test[cat_col] = encoder.transform(test[cat_col])\n","    # Round last float features to 2 decimal place\n","    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","    num_cols = [col for col in num_cols if 'last' in col]\n","    for col in num_cols:\n","        train[col + '_round2'] = train[col].round(2)\n","        test[col + '_round2'] = test[col].round(2)\n","    # Get the difference between last and mean\n","    num_cols = [col for col in train.columns if 'last' in col]\n","    num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n","    for col in num_cols:\n","        try:\n","            train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n","            test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n","        except:\n","            pass\n","    # Transform float64 and float32 to float16\n","    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","    for col in tqdm(num_cols):\n","        train[col] = train[col].astype(np.float16)\n","        test[col] = test[col].astype(np.float16)\n","    # Get feature list\n","    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n","    params = {\n","        'objective': 'binary',\n","        'metric': CFG.metric,\n","        'boosting': CFG.boosting_type,\n","        'seed': CFG.seed,\n","        'num_leaves': 120,#100,\n","        'learning_rate': 0.01,\n","        'feature_fraction': 0.20,\n","        'bagging_freq': 10,\n","        'bagging_fraction': 0.50,\n","        'n_jobs': -1,\n","        'lambda_l2': 2,\n","        'min_data_in_leaf': 40,\n","        }\n","    # Create a numpy array to store test predictions\n","    test_predictions = np.zeros(len(test))\n","    # Create a numpy array to store out of folds predictions\n","    oof_predictions = np.zeros(len(train))\n","    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n","    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n","        print(' ')\n","        print('-'*50)\n","        print(f'Training fold {fold} with {len(features)} features...')\n","        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n","        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n","        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n","        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n","        model = lgb.train(\n","            params = params,\n","            train_set = lgb_train,\n","            num_boost_round = 15500,\n","            valid_sets = [lgb_train, lgb_valid],\n","            early_stopping_rounds = 1500,\n","            verbose_eval = 500,\n","            feval = lgb_amex_metric\n","            )\n","        # Save best model\n","#         joblib.dump(model, f'/content/drive/MyDrive/Amex/Models/lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n","        joblib.dump(model, f'{CFG.input_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n","        \n","        # Predict validation\n","        val_pred = model.predict(x_val)\n","        # Add to out of folds array\n","        oof_predictions[val_ind] = val_pred\n","        # Predict the test set\n","        test_pred = model.predict(test[features])\n","        test_predictions += test_pred / CFG.n_folds\n","        # Compute fold metric\n","        score = amex_metric(y_val, val_pred)\n","        print(f'Our fold {fold} CV score is {score}')\n","        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n","        gc.collect()\n","    # Compute out of folds metric\n","    score = amex_metric(train[CFG.target], oof_predictions)\n","    print(f'Our out of folds CV score is {score}')\n","    # Create a dataframe to store out of folds predictions\n","    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n","#     oof_df.to_csv(f'/content/drive/MyDrive/Amex/OOF/oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n","    oof_df.to_csv(f'{CFG.input_dir}oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n","    \n","    # Create a dataframe to store test prediction\n","    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n","#     test_df.to_csv(f'/content/drive/MyDrive/Amex/Predictions/test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n","    test_df.to_csv(f'{CFG.input_dir}test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n","    \n","seed_everything(CFG.seed)\n","train, test = read_data()\n","train_and_evaluate(train, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4h4IGSdZByf"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"hQKlH5vuVNZF"},"source":["# Read Submission File\n","This is the submission file corresponding to the output of the previous pipeline (using the average blend of 3 seeds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXqsUUenVNZF"},"outputs":[],"source":["# sub = pd.read_csv('../input/amex-sub/test_lgbm_baseline_5fold_seed_blend.csv')\n","# sub.to_csv('test_lgbm_baseline_5fold_seed_blend.csv', index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"amex-lgbm-dart-cv-0-7977.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"094c27799e904ad887bf502d9d5367e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7582498428741679f3245541de307af","IPY_MODEL_0e455acbd2b7437989f9c2538eddf42c","IPY_MODEL_d9a29e84eb26449f9c913b26c0abedb8"],"layout":"IPY_MODEL_64f086d0f76b45689f450977d54c0c5a"}},"0e455acbd2b7437989f9c2538eddf42c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_739ad9f40d26467ba2bb615ea1fffcfa","max":1080,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbcf56b9ffd8432f9db2e147961b0109","value":1080}},"4e910a6ebb4042ceb4cc1df1866f3ea0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64f086d0f76b45689f450977d54c0c5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70be1012bba3409db0325f7c1795bb00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"739ad9f40d26467ba2bb615ea1fffcfa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd22b7312ed6411b82357ebde7f69746":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbcf56b9ffd8432f9db2e147961b0109":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7582498428741679f3245541de307af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd22b7312ed6411b82357ebde7f69746","placeholder":"​","style":"IPY_MODEL_e23a67a309994fc4a8af398930ccb960","value":"100%"}},"d9a29e84eb26449f9c913b26c0abedb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e910a6ebb4042ceb4cc1df1866f3ea0","placeholder":"​","style":"IPY_MODEL_70be1012bba3409db0325f7c1795bb00","value":" 1080/1080 [06:30\u0026lt;00:00, 102.80it/s]"}},"e23a67a309994fc4a8af398930ccb960":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}